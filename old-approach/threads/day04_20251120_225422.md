# Day 4 Thread - Triple Source (arXiv + HN + HF)

**Paper:** In-N-On: Scaling Egocentric Manipulation with in-the-wild and on-task Data
**Authors:** Xiongyi Cai, Ri-Zhao Qiu, Geng Chen
**Published:** 2025-11-19
**URL:** http://arxiv.org/abs/2511.15704v1
**HN Mentions:** 0
**HF Featured:** No
**Generated:** 2025-11-20 22:54
**Generation Time:** 18.7s

---

Here are three tweets about the paper:

Tweet 1:
Existing egocentric manipulation approaches rely on human data for pre-training, but this limits their scalability & effectiveness. In-N-On addresses this by providing a systematic framework for collecting & utilizing in-the-wild and on-task egocentric data.

Tweet 2:
The key insight of In-N-On is that categorizing egocentric data into in-the-wild and on-task categories enables more effective pre-training, as on-task data can be used directly to learn manipulation policies, reducing the need for human pre-training.

Tweet 3:
In-N-On's contribution matters because it paves the way for more scalable & robust manipulation learning from large egocentric datasets, enabling AI systems to perform complex tasks with greater accuracy and reliability in real-world settings.

---
*Generated by Clair Agent - Day 4*
*Stack: Ollama + LangChain + ChromaDB + HN API + HF Scraping*
*Sources: arXiv + HN + HF*
*Cross-references: 0 HN + 0 HF + 0 Triple*