# Day 4 Thread - Triple Source (arXiv + HN + HF)

**Paper:** In-N-On: Scaling Egocentric Manipulation with in-the-wild and on-task Data
**Authors:** Xiongyi Cai, Ri-Zhao Qiu, Geng Chen
**Published:** 2025-11-19
**URL:** http://arxiv.org/abs/2511.15704v1
**HN Mentions:** 0
**HF Featured:** No
**Generated:** 2025-11-20 21:50
**Generation Time:** 86.4s

---

Here are three tweets about the paper:

Tweet 1: Egocentric manipulation datasets remain underutilized due to data heterogeneity. This paper addresses by proposing a scalable approach for collecting & using in-the-wild and on-task egocentric video data, enabling more robust policy learning.

Tweet 2: Key insight: The authors curate a novel dataset PHSD, categorizing human data into in-the-wild and on-task subsets, allowing for systematic analysis of data usage & providing a framework for leveraging diverse egocentric video datasets in manipulation research.

Tweet 3: By addressing the limitations of existing approaches, this paper enables more effective learning of manipulation policies from egocentric videos. This has significant implications for robotics, computer vision, and AI research, driving advancements in human-robot interaction & task automation.

---
*Generated by Clair Agent - Day 4*
*Stack: Ollama + LangChain + ChromaDB + HN API + HF Scraping*
*Sources: arXiv + HN + HF*
*Cross-references: 0 HN + 0 HF + 0 Triple*